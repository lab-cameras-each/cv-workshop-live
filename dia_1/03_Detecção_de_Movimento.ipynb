{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecção de objetos em movimento\n",
    "\n",
    "Para exemplificar uma aplicação de visão computacional em vídeo, vamos realizar a detecção de objetos em movimento (ou regiões em que há movimento) em vídeo.\n",
    "\n",
    "O exercício envolverá a implementação de dois métodos que serão usados em meio ao processo de detecção de movimento.     \n",
    "\n",
    "\n",
    "\n",
    "- **1) Thresholding**: Esse método envolve produzir um imagem que contenha apenas duas cores (com intensidades iguais), geralmente preto e branco, a partir de um threshold (limiar) pré-definido. Abaixo temos um exemplo de como essa função será usada em nosso contexto\n",
    "    \n",
    "<img src=\"https://raw.githubusercontent.com/lab-cameras-each/cv-workshop-live/master/recursos/exemplo_thresholding.png\" alt=\"thresh\" width=\"1400\"/>\n",
    "    \n",
    "    \n",
    "    \n",
    "- **2) Desenho de retângulos**: Esse método deverá, a partir de uma lista de retângulos (definidos por suas coordenadas), desenhá-los na imagem de sáida juntamente com um texto informando o número total de retângulos \n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/lab-cameras-each/cv-workshop-live/master/recursos/retangulos.png\" alt=\"ret\" width=\"500\" />\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#### Os detalhes de implemetanção de cada um dos métodos se encontram ao decorrer deste notebook, no momento em que são necessários.    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "12v3frhwqdv7"
   },
   "outputs": [],
   "source": [
    "# Importação de bibliotecas necessárias\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import io\n",
    "import requests\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "from google.colab.patches import cv2_imshow    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gE0jzgTqtndJ"
   },
   "outputs": [],
   "source": [
    "# Download de vídeo\n",
    "url = 'https://github.com/lab-cameras-each/cv-workshop-live/blob/master/recursos/campus_video.mp4?raw=true'\n",
    "r = requests.get(url, allow_redirects=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "id": "zU_zzu1wuU_x",
    "outputId": "591e8eb8-4836-43cf-b0b8-bea146138d34"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Exibir vídeo\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(r.content).decode()\n",
    "HTML(f\"\"\"\n",
    "<video width=800 controls>\n",
    "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k8CUO5b3uiHC",
    "outputId": "1deb322d-fda8-4258-d841-414fa162a645"
   },
   "outputs": [],
   "source": [
    "# Salvar vídeo em arquivo\n",
    "open('video_original.mp4', 'wb').write(r.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-YQjaU1wS_B"
   },
   "outputs": [],
   "source": [
    "#Armazenar cada frame do video em uma lista\n",
    "cap = cv2.VideoCapture('video_original.mp4')\n",
    "frames = []\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "  \n",
    "    if ret == True:\n",
    "        frames.append(frame)\n",
    "    else: \n",
    "        break\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PPSV-gJfxMqQ",
    "outputId": "2f0ffda6-00b5-42e8-b53c-f4b8bd8be518"
   },
   "outputs": [],
   "source": [
    "#Número de frames\n",
    "len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nvSEcMxbw3bE",
    "outputId": "9c027c61-4586-4bf9-e0c4-61882dd9c531"
   },
   "outputs": [],
   "source": [
    "#Resolução\n",
    "frames[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNXdfps3zN4M"
   },
   "source": [
    "## Detecção de movimento\n",
    "\n",
    "Nas próximas interações, faremos a execução passo-a-passo do algoritmo de detecção de movimento\n",
    "\n",
    "Primeiramente vamos detectar as regioes de movimento entre dois frames do vídeo: o quadro 200 e 201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "id": "Or2DZERMw5r3",
    "outputId": "b04cb4b2-870d-49e6-c194-f3f07e7f4a44"
   },
   "outputs": [],
   "source": [
    "#Exibindo o Frame na posição 200\n",
    "cv2_imshow(frames[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tBZ-LQGSxLN4"
   },
   "outputs": [],
   "source": [
    "weight = 0.6 # Peso dos novos frames na atualização de backgorund\n",
    "avg = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qSgZjTtuzmM0"
   },
   "outputs": [],
   "source": [
    "frame_copy = frames[200].copy() \n",
    "frame_gray = cv2.cvtColor(frame_copy, cv2.COLOR_BGR2GRAY) # Transformação do frame para escala de cinza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "id": "KouS-bbczuAR",
    "outputId": "09e34d06-8867-4702-8575-c229a24d1d4f"
   },
   "outputs": [],
   "source": [
    "cv2_imshow(frame_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P5UGpapwzz5u"
   },
   "outputs": [],
   "source": [
    "# Inicializa background\n",
    "avg = frame_gray.copy().astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R4SU4_QJz4sI",
    "outputId": "2f3e2bdf-22e9-47fb-d4a1-56a5c211f925"
   },
   "outputs": [],
   "source": [
    "#Atualiza a média da imagem de fundo, precisa ser feito no caso de o pano de fundo ser móvel\n",
    "#https://docs.opencv.org/3.4/d7/df3/group__imgproc__motion.html\n",
    "# avg(x,y) = (1−weight)⋅avg(x,y) + weight⋅frame_gray(x,y)\n",
    "cv2.accumulateWeighted(frame_gray, avg, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "id": "3IYxP9Zpz70z",
    "outputId": "a146fb5b-83d1-4f68-c864-e878cd3fdbf3"
   },
   "outputs": [],
   "source": [
    "cv2_imshow(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SHOA8VLD0Cc7"
   },
   "outputs": [],
   "source": [
    "# Diferença em relação a proximo frame\n",
    "frame_copy = frames[201].copy()\n",
    "frame_gray = cv2.cvtColor(frame_copy, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "frameDelta = cv2.absdiff(frame_gray, cv2.convertScaleAbs(avg)) # convertScaleAbs conversao para inteiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 757
    },
    "id": "PmwvKpKl0LtK",
    "outputId": "70d1e8e3-fc85-46a7-cf6a-ad6f4ced70b2"
   },
   "outputs": [],
   "source": [
    "cv2_imshow(frameDelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-SeuWkmA2oGa"
   },
   "outputs": [],
   "source": [
    "#Atualizar média\n",
    "cv2.accumulateWeighted(frame_gray, avg, weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtlhubEq2zUG"
   },
   "source": [
    "### Exercício 1 - Função de thresholding\n",
    "Agora, você deverá implementar a função de threshold conforme a instrução a seguir\n",
    "\n",
    "```python\n",
    "\n",
    "'''\n",
    "apply_threshold: Método de thresholding\n",
    "\n",
    "Se pixel > threshold, entao assume o valor max_value\n",
    "Se pixel <= threshold, entao assume o valor 0\n",
    "\n",
    "\n",
    "Parâmetros:\n",
    "  image (np.array) - Imagem na qual será aplicada a operação\n",
    "  threshold (int) - Valor do limiar para aplicação de thresholding\n",
    "  max_value (int) - Valor máximo que píxel deve assumir se maior que threshold\n",
    "\n",
    "Retorna:\n",
    "  new_image (np.array) - Imagem após aplicação de thresholding\n",
    "\n",
    "'''\n",
    "\n",
    "def apply_threshold(image, threshold, max_value):\n",
    "    new_image = image.copy()\n",
    "    #Aplicação de thresholding\n",
    "    #.\n",
    "    #.\n",
    "    return new_image\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O1gwnv0Y2o2o"
   },
   "outputs": [],
   "source": [
    "#Aplicar threshold\n",
    "thresh = apply_threshold(frameDelta, threshold=5, max_value=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "id": "wyvep-UI2D9g",
    "outputId": "1854112f-1d9f-4a6d-8dcb-c746e4d38a55"
   },
   "outputs": [],
   "source": [
    "cv2_imshow(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "epw0aZCR2X6P"
   },
   "outputs": [],
   "source": [
    "# Encontrando contornos na imagem, ou seja, regiões com aglomerações de píxeis.\n",
    "# No nosso contexto, consideramos que são objetos\n",
    "\n",
    "#Fonte https://github.com/opencv/opencv/blob/master/modules/imgproc/src/contours.cpp\n",
    "contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V63nDPYU2YGU",
    "outputId": "06c59da2-e7cc-4f46-97eb-a2556d53b759"
   },
   "outputs": [],
   "source": [
    "len(contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQjZtTN72YSI"
   },
   "outputs": [],
   "source": [
    "min_area = 400 # Area minima para considerar um contorno como um objeto\n",
    "\n",
    "bounding_boxes = []\n",
    "for c in contours:\n",
    "    \n",
    "    if cv2.contourArea(c) < min_area:\n",
    "        continue\n",
    "        \n",
    "    bounding_boxes.append(cv2.boundingRect(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TkvJXh-3Wvm"
   },
   "source": [
    "### Exercício 2 - Função para desenhar retângulos e texto\n",
    "Agora, você deverá implementar o método que irá desenhar retângulos ao redor dos objetos\n",
    "\n",
    "```python\n",
    "'''\n",
    "draw_info: Método para inserir desenhos dos retângulos e informação de quantidade desses em um frame\n",
    "\n",
    "Parâmetros:\n",
    "  frame (np.array) - Imagem na qual será aplicada a operação\n",
    "  bounding_boxes (list) - Bounding boxes a serem desenhadas\n",
    "\n",
    "Retorna:\n",
    "  frame_draw (np.array) - Imagem após desenho de retângulos\n",
    "\n",
    "'''\n",
    "def draw_info(frame, bounding_boxes):\n",
    "    frame_draw = frame.copy()\n",
    "\n",
    "    # Para cada retângulo em bounding_boxes, inserir seu desenho em frame_draw\n",
    "    #.\n",
    "    #.\n",
    "    # Inserir texto informando quantidade de retângulos (objetos)   \n",
    "    #.\n",
    "    #.\n",
    "        \n",
    "    return frame_draw\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v-qn_OVd2J0T"
   },
   "outputs": [],
   "source": [
    "# Desenho de retângulos e texto\n",
    "frame_draw = draw_info(frames[201], bounding_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "id": "tcm36qJA2q1H",
    "outputId": "3b77becc-0da3-41eb-9ebc-6c298adb380f"
   },
   "outputs": [],
   "source": [
    "cv2_imshow(frame_draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "smMsHVeS2vIl"
   },
   "outputs": [],
   "source": [
    "# Função final. \n",
    "# Essa função já esta definida e utiliza os métodos que você implementou anteriormente\n",
    "\n",
    "# A função detecta objetos em movimento considerando o frame passado como parametro e a média (avg), desenhado os retângulos na cena\n",
    "def detect_movement_frame(frame, avg, weight=0.6, min_area=400):\n",
    "    frame_copy = frame.copy()\n",
    "    frame_gray = cv2.cvtColor(frame_copy, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if avg is None:\n",
    "        avg = frame_gray.copy().astype(\"float\")\n",
    "\n",
    "    frameDelta = cv2.absdiff(frame_gray, cv2.convertScaleAbs(avg))\n",
    "    cv2.accumulateWeighted(frame_gray, avg, weight)\n",
    "\n",
    "    thresh = apply_threshold(frameDelta, threshold=5, max_value=255) # Implementar\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    bounding_boxes = []\n",
    "    for c in contours:\n",
    "        # Ignorar se menor que área minima\n",
    "        if cv2.contourArea(c) < min_area:\n",
    "            continue\n",
    "        bounding_boxes.append(cv2.boundingRect(c))\n",
    "        \n",
    "        \n",
    "    return bounding_boxes, avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wwhHExm93EUh"
   },
   "outputs": [],
   "source": [
    "# Aplicar detecção de objetos em movimento para todos os frames do vídeo\n",
    "\n",
    "cap = cv2.VideoCapture('video_original.mp4') # Abir vídeo\n",
    "frame_width = int(cap.get(3)) # Obtém largura do vídeo para usar no arquivo de sáida\n",
    "frame_height = int(cap.get(4))# Obtém altura do vídeo para usar no arquivo de sáida\n",
    "\n",
    "# Arquivo de vídeo de saída\n",
    "out = cv2.VideoWriter('video_processado.avi',cv2.VideoWriter_fourcc(*'XVID'), 30, (frame_width,frame_height))\n",
    "\n",
    "avg = None\n",
    "while(cap.isOpened()): # Enquanto vídeo não chegar ao fim\n",
    "    ret, frame = cap.read() # Lê próximo frame\n",
    "    \n",
    "    if ret == True: # Se leitura feita com sucesso\n",
    "        bounding_boxes, avg = detect_movement_frame(frame, avg, weight=0.6, min_area=800) # Detecta objetos em movimento e os desenha     \n",
    "        if len(bounding_boxes) > 0: # Se há objetos\n",
    "             frame = draw_info(frame, bounding_boxes) # Desenha retângulos correspondentes\n",
    "\n",
    "        out.write(frame) # Escreve frame no aquivo de vídeo de sáida\n",
    "    else: \n",
    "        break\n",
    "\n",
    "cap.release() # Fecha vídeo de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QxCVrlAJvhwo",
    "outputId": "3511427a-2089-4960-eeb0-e82b3879c5ad"
   },
   "outputs": [],
   "source": [
    "\n",
    "!ffmpeg -i video_processado.avi video_processado.mp4 -y # Conversão de avi para mp4 (suportando por google colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "id": "4hxpvMww46-4",
    "outputId": "04532270-d467-4511-fa38-85e140adc0d4"
   },
   "outputs": [],
   "source": [
    "# Exibição do vídeo final\n",
    "\n",
    "f = open('video_processado.mp4', 'rb')\n",
    "video_processado = f.read()\n",
    "\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(video_processado).decode()\n",
    "HTML(f\"\"\"\n",
    "<video width=800 controls>\n",
    "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibZLcC9O3RSH"
   },
   "source": [
    "Para ir além:\n",
    "- Rodar localmente (Jupyter Notebook)\n",
    "- Mostrar vídeo enquanto faz a leitura\n",
    "- Tentar fazer adaptação para rodar localmente usando webcam"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "03 - Detecção de Movimento.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
