{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "DNN_Classification_OpenCV_colab_aluno.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed62bc19"
      },
      "source": [
        "<center><h1> Usando Modelos de Deep Learning com apoio do OpenCV </h1></center>\n",
        "<center><h1> Classificação de Imagens </h1></center>"
      ],
      "id": "ed62bc19"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d83801ce"
      },
      "source": [
        "<h2>1 - As bibliotecas/pacotes pré-requisitos para este workshop são:</h2>\n",
        "\n",
        "<ul>\n",
        "    <li>OpenCV</li>\n",
        "    <li>Matplotlib</li>\n",
        "    <li>Numpy</li>\n",
        "</ul>\n",
        "<h3>Inicialmente, será necessário atualizar a versão do OpenCV para 4.5 ou maior.\n",
        "<ul>\n",
        "    <li>Executar a célula abaixo (que contém o comando 'pip install opencv-python --upgrade')</li>\n",
        " \n",
        "</ul>\n",
        "\n"
      ],
      "id": "d83801ce"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA8az18zKlqE"
      },
      "source": [
        "!pip install opencv-python --upgrade"
      ],
      "id": "uA8az18zKlqE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCco8XaPK69J"
      },
      "source": [
        "<ul>\n",
        "    <li>Importar a biblioteca do OpenCV e confirmar a versão que está sendo usada é 4.5 ou maior.</li>\n",
        " \n",
        "</ul>\n"
      ],
      "id": "kCco8XaPK69J"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWokrvu-K3fR"
      },
      "source": [
        "# Importar o OpenCV\n",
        "import cv2\n",
        "print(\"OpenCV version:\", cv2.__version__)"
      ],
      "id": "aWokrvu-K3fR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c7ca13a"
      },
      "source": [
        "# Importar as demais bibliotecas/pacotes necessários ao projeto\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import requests\n",
        "from google.colab.patches import cv2_imshow \n",
        "\n",
        "## Acesso ao google drive a partir do colab\n",
        "from google.colab import drive\n",
        "#drive.mount('/content/gdrive') \n",
        "drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "\n",
        "## IMPORTANTE:\n",
        "## Pré-requisitos para a configuração de acesso aos recursos do workshop:\n",
        "## 1. A pasta 'recursos_workshop' deve ter sido compartilhada com o seu usuário do Google Drive\n",
        "## 2. O aluno deverá fazer acesso à pasta compartilhada em sua conta de Google Drive\n",
        "## 3. O aluno deverá criar um atalho (shortcut) para a pasta compartilhada. \n",
        "##    Este atalho ficará localizado no próprio drive do aluno ('Meu Drive' ou 'MyDrive') e\n",
        "##    terá o nome 'recursos_workshop'\n",
        "\n",
        "\n",
        "## Caminho para a pasta de recursos do workshop\n",
        "resources_path = \"gdrive/MyDrive/recursos_workshop/\"\n",
        "\n",
        "## Caminho para a pasta de modelos de Deep Learning\n",
        "models_path = resources_path + \"modelos_DL/\"\n",
        "\n",
        "## Caminho para a pasta de imagens \n",
        "image_dir = resources_path + \"imagens\"\n",
        "\n"
      ],
      "id": "3c7ca13a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a19fdc6"
      },
      "source": [
        "## 2 - Configurações: diretórios de modelos, imagens, notebooks \n",
        "#### definições/configurações de modelos de Deep Learning e pesos pré-treinados: \n",
        "<ul>\n",
        "<li>Estão localizados na pasta 'recursos_workshop' do Google drive</li>\n",
        "</ul>\n",
        "\n",
        "#### imagens:\n",
        "<ul>  \n",
        "    <li>Também estão no google drive ou, dependendo do caso, serão baixadas da internet</li>\n",
        "</ul>\n",
        "    \n"
      ],
      "id": "6a19fdc6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b6ef0a4"
      },
      "source": [
        "## 3 - Leitura de imagens e pré-processamento \n",
        "### 3.1 - A imagem pode ser lida do disco usando o método \"imread\" do OpenCV\n",
        "<ul>\n",
        "    <li>cv2.imread</li>    \n",
        "</ul>\n",
        "\n",
        "### 3.2 - O método \"blobFromImage\" permite fazer resize, crop, scaling, normalizing, mudar de RGB para BGR.\n",
        "### 3.3 - Este método produz um BLOB de 4 dimensões \n",
        "<ul>\n",
        "    <li>cv2.dnn.blobFromImage</li>\n",
        "    <li>cv2.dnn.blobFromImages</li>    \n",
        "</ul>\n"
      ],
      "id": "4b6ef0a4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a20324c"
      },
      "source": [
        "## 4 - Frameworks e modelos\n",
        "### 4.1 - Os seguintes frameworks são suportados pelo módulo <a href=\"https://github.com/opencv/opencv/tree/master/modules/dnn\" target=\"_blank\" rel=\"noopener noreferrer\">DNN</a> do OpenCV\n",
        "\n",
        "<ul>\n",
        "<li><a href=\"http://caffe.berkeleyvision.org/\" target=\"_blank\" rel=\"noopener noreferrer\">Caffe</a></li>\n",
        "<li><a href=\"https://www.tensorflow.org/\" target=\"_blank\" rel=\"noopener noreferrer\">Tensorflow</a></li>\n",
        "<li><a href=\"http://torch.ch/\" target=\"_blank\" rel=\"noopener noreferrer\">Torch</a></li>\n",
        "<li><a href=\"https://pjreddie.com/darknet/\" target=\"_blank\" rel=\"noopener noreferrer\">Darknet</a></li>\n",
        "<li><a href=\"https://onnx.ai/\" target=\"_blank\" rel=\"noopener noreferrer\">ONNX</a></li>\n",
        "</ul>    \n"
      ],
      "id": "2a20324c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "990c081c"
      },
      "source": [
        "## 5 - Carga em memória de modelos de DNN (a partir de modelo serializado em disco)\n",
        "### OpenCV usa modelos pré-treinados em datasets com acesso público (por exemplo, ImageNet). Esses modelos são desenvolvidos com o uso de diversos frameworks (Caffe, Tensorflow, Pytorch, etc.)\n",
        "<ul>\n",
        "    <li>cv2.dnn.readNetFromCaffe</li>\n",
        "    <li>cv2.dnn.readNetFromDarknet</li>\n",
        "    <li>cv2.dnn.readNetFromTensorFlow</li>\n",
        "    <li>cv2.dnn.readNetFromTorch</li>\n",
        "    <li>cv2.dnn.readNetFromONNX</li>\n",
        "</ul>"
      ],
      "id": "990c081c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89d002b6"
      },
      "source": [
        "## 6 - O processo de inferência usando o modelo\n",
        "### 6.1 - Definindo o input para o modelo e iniciando a inferência\n",
        "\n",
        "<ul>\n",
        "<li>setInput(blob)</li>\n",
        "<li>forward</li>\n",
        "</ul>"
      ],
      "id": "89d002b6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c993f013"
      },
      "source": [
        "## 7 - Classificação de imagens\n",
        "### A classificação é a tarefa de categorizar uma imagem com base em um conjunto pré-definido de classes.\n",
        "### Logo abaixo, iremos definir algumas funções de apoio para as nossas tarefas."
      ],
      "id": "c993f013"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ce8af74"
      },
      "source": [
        "### 7.1 - Carregar o modelo <a href=\"https://arxiv.org/abs/1409.4842\" target=\"_blank\" rel=\"noopener noreferrer\">GoogLeNet</a> (desenvolvido com uso do framework Caffe) na memória"
      ],
      "id": "4ce8af74"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "109cb2cc"
      },
      "source": [
        "def loadNetModel(caffe_dir, caffe_model, caffe_proto):\n",
        "    model = os.path.join(caffe_dir, caffe_model)\n",
        "    proto = os.path.join(caffe_dir, caffe_proto)\n",
        "    net = cv2.dnn.readNetFromCaffe(proto, model)\n",
        "    return net"
      ],
      "id": "109cb2cc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e160e593"
      },
      "source": [
        "### 7.2 - Obter os nomes das classes associadas às predições a partir do dataset 'classes_file'"
      ],
      "id": "e160e593"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90ec6c67"
      },
      "source": [
        "def getClassNames(caffe_dir, classes_file):\n",
        "    labs_fpath = os.path.join(caffe_dir, classes_file)\n",
        "    cfile = open(labs_fpath)\n",
        "    file_rows = cfile.read().strip().split(\"\\n\")\n",
        "    classes = [row[row.find(\" \") + 1:].split(\",\")[0] for row in file_rows]\n",
        "    return classes"
      ],
      "id": "90ec6c67",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe28bf99"
      },
      "source": [
        "### 7.3 - Utilizando OpenCV, ler a imagem do arquivo 'image_file'  do diretório 'image_dir'"
      ],
      "id": "fe28bf99"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff83bee7"
      },
      "source": [
        "def getImageAndBlob(image_dir, image_file):\n",
        "    # Read image from disk\n",
        "    image = cv2.imread(os.path.join(image_dir, image_file))\n",
        "    # Pre-process image and obtain blob\n",
        "    blob = cv2.dnn.blobFromImage(image, 1, (224, 224), (104, 117, 123))\n",
        "    return image, blob "
      ],
      "id": "ff83bee7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc5edb69"
      },
      "source": [
        "### 7.4 - Definir a imagem lida como entrada para o processamento do modelo"
      ],
      "id": "bc5edb69"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7de05efb"
      },
      "source": [
        "def setNetInput(net, blob):\n",
        "    #set input \n",
        "    net.setInput(blob)\n",
        "    return net"
      ],
      "id": "7de05efb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff099531"
      },
      "source": [
        "### 7.5 - Processar a inferência neste modelo, usando esta imagem "
      ],
      "id": "ff099531"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06ca8a53"
      },
      "source": [
        "# O blob da imagem a ser usado como input para o modelo realizar a inferência\n",
        "# precisa já ter sido definido antes de acionar esta função\n",
        "def processInference(net):\n",
        "    #forward\n",
        "    predictions = net.forward()\n",
        "    return predictions"
      ],
      "id": "06ca8a53",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6300917"
      },
      "source": [
        "### 7.6 - As predições do modelo apresentam um índice de confiança como resultado. Ordenar em ordem descendente essas predições e obter as 'qtd_preds' com maior índice de confiança"
      ],
      "id": "f6300917"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d59e85f7"
      },
      "source": [
        "def getOrderedPreds(predictions, qtd_preds):\n",
        "    # argsort ordena em ordem ascendente\n",
        "    ind_sorted = np.argsort(predictions[0])\n",
        "    # obter o tamanho do slice que contém as últimas 'qtd_preds' desejadas\n",
        "    last = len(predictions[0])\n",
        "    lastn = last - qtd_preds\n",
        "    # obter as últimas 'qtd_preds' da lista em ordem descendente\n",
        "    ordered_indexes = ind_sorted[lastn: last][::-1]\n",
        "    return ordered_indexes"
      ],
      "id": "d59e85f7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23266fa5"
      },
      "source": [
        "### 7.7 - Mostrar as predições com maior índice de confiança"
      ],
      "id": "23266fa5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba70f8f4"
      },
      "source": [
        "# exibe as predições com maior índice de confiança\n",
        "def printPredictions(ordered_indexes, classes, predictions, image_file):\n",
        "    print(\"Índice de confiança das predições de classes para a imagem:\", image_file)\n",
        "    print(\"Ranking\\t\\tclasse\\t\\t\\tconf.index\\t\\t\\tclassnum\")\n",
        "    for (i, idx) in enumerate(ordered_indexes):\n",
        "        print(\"{:<10} \\t{:<20} \\t{:.5} \\t\\t\\t{:<10}\".format(i + 1, classes[idx], predictions[0][idx], str(idx)))\n"
      ],
      "id": "ba70f8f4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29f82c5d"
      },
      "source": [
        "### 7.8 - Inserir na imagem o nome da classe que apresentou o maior índice de confiança"
      ],
      "id": "29f82c5d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b6ce6ab"
      },
      "source": [
        "def putTextInImage(image, ordered_indexes, classes, predictions):\n",
        "    itop = ordered_indexes[0]\n",
        "    text = \"Classe: {}, Conf: {:.2f}%\".format(classes[itop], predictions[0][itop] * 100)\n",
        "    cv2.putText(image, text, (3, 15),  cv2.FONT_HERSHEY_SIMPLEX, 0.6, (10, 10, 255), 2) \n",
        "    return image            "
      ],
      "id": "6b6ce6ab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56ca6a3b"
      },
      "source": [
        "### 7.9 - Exibir a imagem usando OpenCV"
      ],
      "id": "56ca6a3b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "083ce423"
      },
      "source": [
        "def imageResize(frame, maxH):\n",
        "    h, w = frame.shape[:2] # obter a altura e largura do frame\n",
        "    if maxH < h:\n",
        "        aspect_ratio = w/h\n",
        "        blob_height = maxH \n",
        "        blob_width = int(blob_height * aspect_ratio)\n",
        "        dsize = (blob_width, blob_height) # keep the frame's original aspect ratio\n",
        "        return cv2.resize(frame, dsize)\n",
        "    return frame\n",
        "\n",
        "def showImage(image):\n",
        "    heightMax = 600  # max height used here to do a imshow inside Colab\n",
        "    out = imageResize(image, heightMax)\n",
        "    cv2_imshow(out)\n"
      ],
      "id": "083ce423",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94084cd8"
      },
      "source": [
        "### 7.10 - Implementação da classificação da imagem contida em 'image_file' e exibição dos resultados"
      ],
      "id": "94084cd8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fedc669b"
      },
      "source": [
        "def classifyAndDisplayImage(net, classes, image_dir, image_file, qtd_preds):\n",
        "\n",
        "    # Utilizando o framework Caffe, o modelo GoogLeNet e os nomes das classes associadas às predições,\n",
        "    # processar a classificação da imagem informada\n",
        "\n",
        "    # 7.3 - Utilizando OpenCV, ler a imagem do arquivo 'image_file' do diretório 'image_dir'\n",
        "    image, blob = getImageAndBlob(image_dir, image_file)\n",
        "\n",
        "\n",
        "    # 7.4 - Definir a imagem lida como entrada para o processamento do modelo\n",
        "    net = setNetInput(net, blob)\n",
        "\n",
        "\n",
        "    # 7.5 - Processar a inferência neste modelo, usando esta imagem\n",
        "    predictions = processInference(net)\n",
        "\n",
        "\n",
        "    # 7.6 - As predições do modelo apresentam um índice de confiança como resultado. Ordenar em ordem descendente essas predições e obter as 'qtd_preds' com maior índice de confiança\n",
        "    ordered_indexes = getOrderedPreds(predictions, qtd_preds)\n",
        "\n",
        "    # 7.7 - Mostrar as predições com maior índice de confiança\n",
        "    printPredictions(ordered_indexes, classes, predictions, image_file)\n",
        "\n",
        "\n",
        "    # 7.8 - Inserir na imagem o nome da classe que apresentou o maior índice de confiança\n",
        "    image = putTextInImage(image, ordered_indexes, classes, predictions)\n",
        "\n",
        "    # 7.9 - Exibir a imagem usando OpenCV\n",
        "    showImage(image)\n",
        "\n",
        "    "
      ],
      "id": "fedc669b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2035958"
      },
      "source": [
        "### 7.11 - Acionamento do processo de classificação de imagens utilizando as funções de apoio\n",
        "#### 7.11.1 - Definições de configuração: diretórios de modelos, imagens; arquivos de modelos e classes\n"
      ],
      "id": "f2035958"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2179d80a"
      },
      "source": [
        "# Definições de diretórios, arquivos de modelo, pesos\n",
        "\n",
        "###  A definição do diretório de imagens está no início deste notebook\n",
        "\n",
        "\n",
        "# definir o diretório onde está armazenado o modelo a ser usado\n",
        "caffe_dir = models_path + 'Googlenet'\n",
        "\n",
        "# definir o arquivo que contém os pesos pré-treinados deste modelo \n",
        "caffe_model = 'bvlc_googlenet.caffemodel'\n",
        "\n",
        "# definir o arquivo que contém a 'configuração' deste modelo \n",
        "caffe_proto = 'bvlc_googlenet.prototxt'\n",
        "\n",
        "# definir o arquivo que contém as classes utilizadas para treinar o modelo\n",
        "classes_file = \"synset_words.txt\"\n",
        "#\n",
        "#"
      ],
      "id": "2179d80a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "904b1a7f"
      },
      "source": [
        "#### 7.11.2 - Fazer a carga do modelo na memória e obter as classes (rótulos) utilizadas no treinamento do modelo\n"
      ],
      "id": "904b1a7f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fbd1e5d"
      },
      "source": [
        "# Inicialmente, fazer a carga do modelo na memória e obter as classes (rótulos) utilizadas\n",
        "# no treinamento do modelo\n",
        "\n",
        "# 7.1 - Utilizando o framework Caffe, carregar o modelo GoogLeNet na memória\n",
        "net = loadNetModel(caffe_dir, caffe_model, caffe_proto)\n",
        "\n",
        "# 7.2 - Obter os nomes das classes associadas às predições a partir do dataset 'classes_file'\n",
        "classes = getClassNames(caffe_dir, classes_file)\n",
        "\n",
        "# definir quantidade de predições que queremos mostrar, neste caso queremos exibir as 3 predições com maior índice de confiança\n",
        "qtd_preds = 3\n",
        "#"
      ],
      "id": "9fbd1e5d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "340089ad"
      },
      "source": [
        "#### 7.11.3 - Definir a imagem a ser processada e acionar o processo de classificação"
      ],
      "id": "340089ad"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a180a8b"
      },
      "source": [
        "# definir a imagem a ser processada\n",
        "image_file = 'eagle.png' \n",
        "\n",
        "# Processar a classificação da imagem contida no arquivo 'image_file' \n",
        "classifyAndDisplayImage(net, classes, image_dir, image_file, qtd_preds)\n"
      ],
      "id": "6a180a8b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "998b012b"
      },
      "source": [
        "### Atividade para o aluno\n",
        "#### 7.11.4 - Exercício: utilizando o modelo já carregado, efetuar a classificação para as seguintes imagens\n",
        "<ul>\n",
        "<li>pexels-david-dibert-635499.jpg</li>\n",
        "<li>pexels-engin-akyurt-1769271.jpg</li>\n",
        "<li>pexels-frank-grün-3757197.jpg</li>\n",
        "<li>pexels-pascal-renet-1089304.jpg</li>\n",
        "<li>pexels-pixabay-53114.jpg</li>\n",
        "</ul>"
      ],
      "id": "998b012b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e80e88b0"
      },
      "source": [
        "### 7.12 - Outro exemplo: classificação de imagens usando o framework Darknet\n",
        "#### Primeiramente, vamos definir algumas funções de apoio"
      ],
      "id": "e80e88b0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56737787"
      },
      "source": [
        "def darknetGetClassNames(darknet_dir, classes_file):\n",
        "    labs_fpath = os.path.join(darknet_dir, classes_file)\n",
        "    cfile = open(labs_fpath)\n",
        "    file_rows = cfile.read().strip().split(\"\\n\")\n",
        "    classes = [row for row in file_rows] #[row[row.find(\" \") + 1:].split(\",\")[0] for row in file_rows]\n",
        "    return classes"
      ],
      "id": "56737787",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79a9adf8"
      },
      "source": [
        "def darknetGetImageAndBlob(image_dir, image_file):\n",
        "    imagec = cv2.imread(os.path.join(image_dir, image_file))\n",
        "    # Pre-process image and obtain blob\n",
        "    blobc = cv2.dnn.blobFromImage(imagec,  1/255.0, (256, 256), swapRB=True, crop=False)\n",
        "    return imagec, blobc\n"
      ],
      "id": "79a9adf8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8887395"
      },
      "source": [
        "def loadDarknetClassifModel(darknet_dir, darknet_model, darknet_proto):\n",
        "    model = os.path.join(darknet_dir, darknet_model)\n",
        "    proto = os.path.join(darknet_dir, darknet_proto)\n",
        "    dnet = cv2.dnn.readNetFromDarknet(proto, model)\n",
        "    dnet.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
        "    return dnet\n"
      ],
      "id": "e8887395",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f54221f9"
      },
      "source": [
        "def darknetClassifyAndShowResults(image_dir, image_file, dnet):\n",
        "    imagec, blobc = darknetGetImageAndBlob(image_dir, image_file)\n",
        "\n",
        "    # 7.4 - Definir a imagem lida como entrada para o processamento do modelo\n",
        "    dnet = setNetInput(dnet, blobc)\n",
        "\n",
        "    # 7.5 - Processar a inferência neste modelo, usando esta imagem\n",
        "    outputs = processInference(dnet)\n",
        "    #\n",
        "    # output is a list with 1 element with shape (1, 1000, 1, 1)\n",
        "    # reshape it to (1, 1000) - the shape expected in getOrderedPreds function\n",
        "\n",
        "    out0 = outputs[0]\n",
        "    dnet_preds = out0.reshape(out0.shape[1], out0.shape[0])\n",
        "    dnet_ordered_inds = getOrderedPreds(dnet_preds, qtd_preds)\n",
        "\n",
        "    printPredictions(dnet_ordered_inds, darknet_classes, dnet_preds, image_file)\n",
        "\n",
        "\n",
        "    # 7.8 - Inserir na imagem o nome da classe que apresentou o maior índice de confiança\n",
        "    image = putTextInImage(imagec, dnet_ordered_inds, darknet_classes, dnet_preds)\n",
        "\n",
        "    # 7.9 - Exibir a imagem usando OpenCV\n",
        "    showImage(image)\n"
      ],
      "id": "f54221f9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkRHX-ZafiZ1"
      },
      "source": [
        "#### Inicialmente, utilizaremos o modelo darknet19 para efetuar classificação de imagens"
      ],
      "id": "lkRHX-ZafiZ1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf3fdd00"
      },
      "source": [
        "# Testes com darknet 19 para classificação\n",
        "#\n",
        "# definir o diretório onde está armazenado o modelo a ser usado\n",
        "#\n",
        "darknet_dir = models_path + 'Darknet/darknet_classif'\n",
        "\n",
        "\n",
        "# definir o arquivo que contém os pesos pré-treinados deste modelo \n",
        "darknet_model = 'darknet19.weights'\n",
        "\n",
        "# definir o arquivo que contém a 'configuração' deste modelo \n",
        "darknet_proto = 'darknet19.cfg'\n",
        "\n",
        "# arquivo com os nomes das classes\n",
        "darknet_classes_file = 'imagenet.shortnames.list'\n",
        "\n",
        "darknet_classes = darknetGetClassNames(darknet_dir, darknet_classes_file) #getClassNames(darknet_dir, darknet_classes_file) #\n",
        "\n",
        "#\n",
        "dnet = loadDarknetClassifModel(darknet_dir, darknet_model, darknet_proto)\n",
        "\n",
        "# determine the output layer\n",
        "ln = dnet.getLayerNames()\n",
        "ln = [ln[i[0] - 1] for i in dnet.getUnconnectedOutLayers()]\n",
        "\n",
        "#\n",
        "\n"
      ],
      "id": "cf3fdd00",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a4745dc"
      },
      "source": [
        "#### 7.12.1 - Agora, iremos classificar uma imagem usando o modelo já carregado em memória"
      ],
      "id": "3a4745dc"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46b67324"
      },
      "source": [
        "# definir a imagem a ser processada\n",
        "image_file = 'eagle.png' \n",
        "  \n",
        "\n",
        "darknetClassifyAndShowResults(image_dir, image_file, dnet)\n"
      ],
      "id": "46b67324",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDLxT462Ymdm"
      },
      "source": [
        "### Atividade para o aluno\n",
        "#### 7.12.2 - Exercício: utilizando o modelo já carregado, efetuar a classificação para as seguintes imagens\n",
        "<ul>\n",
        "<li>pexels-engin-akyurt-1769271.jpg</li>\n",
        "<li>pexels-pascal-renet-1089304.jpg</li>\n",
        "</ul>"
      ],
      "id": "mDLxT462Ymdm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3obmbODZOaG"
      },
      "source": [
        "### Atividade para o aluno\n",
        "#### 7.12.3 - Exercício: tendo como base o exemplo acima, usar a rede darknet de referência para efetuar a classificação de imagens. O arquivo de classes será o mesmo já definido acima. Utilizar os seguintes arquivos referentes à configuração e aos pesos do modelo:\n",
        "<ul>\n",
        "<li>Modelo: 'darknet_reference.weights'</li>\n",
        "<li>Config: 'darknet_reference.cfg'</li>\n",
        "</ul>"
      ],
      "id": "U3obmbODZOaG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joSI0PuWbUgl"
      },
      "source": [
        "### Atividade para o aluno\n",
        "#### 7.12.4 - Exercício: utilizando o modelo darknet de referência já carregado, efetuar a classificação para as seguintes imagens\n",
        "<ul>\n",
        "<li>pexels-anel-rossouw-2558605.jpg</li>\n",
        "<li>pexels-frank-grün-3757197.jpg</li>\n",
        "</ul>"
      ],
      "id": "joSI0PuWbUgl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFUIR0bdb4Dv"
      },
      "source": [
        "### Atividade para o aluno\n",
        "#### 7.12.5 - Exercício: tendo como base o exemplo acima, usar a rede densenet 201 para efetuar a classificação de imagens. O arquivo de classes será o mesmo já definido acima. Utilizar os seguintes arquivos referentes à configuração e aos pesos do modelo:\n",
        "<ul>\n",
        "<li>Modelo: 'densenet201.weights'</li>\n",
        "<li>Config: 'densenet201.cfg'</li>\n",
        "</ul>"
      ],
      "id": "YFUIR0bdb4Dv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMTw9a7ucgMv"
      },
      "source": [
        "### Atividade para o aluno\n",
        "#### 7.12.6 - Exercício: utilizando o modelo densenet 201 já carregado, efetuar a classificação para as seguintes imagens\n",
        "<ul>\n",
        "<li>pexels-anel-rossouw-2558605.jpg</li>\n",
        "<li>pexels-pascal-renet-1089304.jpg</li>\n",
        "<li>pexels-frank-grün-3757197.jpg</li>\n",
        "</ul>"
      ],
      "id": "uMTw9a7ucgMv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KgtMRoviaDV"
      },
      "source": [
        "### Atividade para o aluno\n",
        "#### 7.12.7 - Questões\n",
        "<ul>\n",
        "<li>Por que utilizamos o mesmo arquivo de classes nas atividades relacionadas aos modelos densenet 201, darknet19, darknet de referência?</li>\n",
        "<li>Com base nas classificações obtidas para as diferentes imagens, é possível dizer se algum dos modelos vistos é melhor que os demais?</li>\n",
        "</ul>"
      ],
      "id": "-KgtMRoviaDV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRpClIn6jm3g"
      },
      "source": [
        "### Atividade para o aluno\n",
        "#### 7.12.8 - Atividades extras\n",
        "<ul>\n",
        "<li>Efetuar a classificação de todas as imagens contidas no diretório e gravar em outra pasta de sua escolha as imagens obtidas ao final do processo de classificação.</li>\n",
        "<li>Melhorar a atividade descrita acima, gravando os arquivos de imagens que possuem nomes com prefixo 'pexel', com nomes que representem suas respectivas classes. Por exemplo, o arquivo de nome cat.jpg será o arquivo que contém uma imagem cuja classificação com maior índice de confiança é 'cat'.</li>\n",
        "</ul>"
      ],
      "id": "lRpClIn6jm3g"
    }
  ]
}